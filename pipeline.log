üßº [1/9] Removing existing connectors (if any)
‚û°Ô∏è Deleting postg-connector-ipca...
‚û°Ô∏è Deleting postg-connector-pre...
‚û°Ô∏è Deleting s3-sink-ipca...
‚û°Ô∏è Deleting s3-sink-pre...
üöÄ [2/9] Starting containers with Docker Compose...
‚è≥ [3/9] Waiting for Kafka Connect to become available (timeout: 60s)
üõ†Ô∏è [4/9] Creating PostgreSQL tables if needed...
üìÑ [5/9] Generating connector config files from templates...
üì¶ [6/9] Copying configuration files into the container...
üîå [7/9] Registering JDBC source connectors...
{
  "name": "postg-connector-ipca",
  "config": {
    "connector.class": "io.confluent.connect.jdbc.JdbcSourceConnector",
    "tasks.max": "1",
    "connection.url": "jdbc:postgresql://postgres:5432/postgres",
    "connection.user": "postgres",
    "connection.password": "Jp1987",
    "mode": "bulk",
    "table.whitelist": "public.postg_ipca",
    "topic.prefix": "postgres-",
    "validate.non.null": "false",
    "poll.interval.ms": "5000",
    "name": "postg-connector-ipca"
  },
  "tasks": [],
  "type": "source"
}
{
  "name": "postg-connector-pre",
  "config": {
    "connector.class": "io.confluent.connect.jdbc.JdbcSourceConnector",
    "tasks.max": "1",
    "connection.url": "jdbc:postgresql://postgres:5432/postgres",
    "connection.user": "postgres",
    "connection.password": "Jp1987",
    "mode": "bulk",
    "table.whitelist": "public.postg_pre",
    "topic.prefix": "postgres-",
    "validate.non.null": "false",
    "poll.interval.ms": "5000",
    "name": "postg-connector-pre"
  },
  "tasks": [],
  "type": "source"
}
‚òÅÔ∏è [8/9] Registering S3 Sink connectors...
{
  "name": "s3-sink-ipca",
  "config": {
    "connector.class": "io.confluent.connect.s3.S3SinkConnector",
    "tasks.max": "1",
    "topics": "postgres-postg_ipca",
    "s3.bucket.name": "xp-etl-pipeline",
    "s3.region": "us-east-1",
    "flush.size": "1",
    "storage.class": "io.confluent.connect.s3.storage.S3Storage",
    "format.class": "io.confluent.connect.s3.format.json.JsonFormat",
    "value.converter": "org.apache.kafka.connect.json.JsonConverter",
    "value.converter.schemas.enable": "false",
    "key.converter": "org.apache.kafka.connect.storage.StringConverter",
    "schema.compatibility": "NONE",
    "topics.dir": "raw/kafka/ipca",
    "name": "s3-sink-ipca"
  },
  "tasks": [],
  "type": "sink"
}
{
  "name": "s3-sink-pre",
  "config": {
    "connector.class": "io.confluent.connect.s3.S3SinkConnector",
    "tasks.max": "1",
    "topics": "postgres-postg_pre",
    "s3.bucket.name": "xp-etl-pipeline",
    "s3.region": "us-east-1",
    "flush.size": "1",
    "storage.class": "io.confluent.connect.s3.storage.S3Storage",
    "format.class": "io.confluent.connect.s3.format.json.JsonFormat",
    "value.converter": "org.apache.kafka.connect.json.JsonConverter",
    "value.converter.schemas.enable": "false",
    "key.converter": "org.apache.kafka.connect.storage.StringConverter",
    "schema.compatibility": "NONE",
    "topics.dir": "raw/kafka/pre",
    "name": "s3-sink-pre"
  },
  "tasks": [],
  "type": "sink"
}
‚úÖ [9/9] Pipeline started successfully. Connectors are active, topics are being monitored, and S3 is ready for ingestion.
üßæ Logging status of all connectors...
üîç Status for postg-connector-ipca:
{
  "name": "postg-connector-ipca",
  "connector": {
    "state": "RUNNING",
    "worker_id": "connect:8083"
  },
  "tasks": [
    {
      "id": 0,
      "state": "FAILED",
      "worker_id": "connect:8083",
      "trace": "org.apache.kafka.common.config.ConfigException: Task is being killed because it was not assigned a table nor a query to execute. If run in table mode please make sure that the tables exist on the database. If the table does exist on the database, we recommend using the fully qualified table name.\n\tat io.confluent.connect.jdbc.source.JdbcSourceTask.start(JdbcSourceTask.java:113)\n\tat org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.initializeAndStart(AbstractWorkerSourceTask.java:274)\n\tat org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:200)\n\tat org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:257)\n\tat org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.run(AbstractWorkerSourceTask.java:75)\n\tat org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:181)\n\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
    }
  ],
  "type": "source"
}
üîç Status for postg-connector-pre:
{
  "name": "postg-connector-pre",
  "connector": {
    "state": "RUNNING",
    "worker_id": "connect:8083"
  },
  "tasks": [
    {
      "id": 0,
      "state": "FAILED",
      "worker_id": "connect:8083",
      "trace": "org.apache.kafka.common.config.ConfigException: Task is being killed because it was not assigned a table nor a query to execute. If run in table mode please make sure that the tables exist on the database. If the table does exist on the database, we recommend using the fully qualified table name.\n\tat io.confluent.connect.jdbc.source.JdbcSourceTask.start(JdbcSourceTask.java:113)\n\tat org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.initializeAndStart(AbstractWorkerSourceTask.java:274)\n\tat org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:200)\n\tat org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:257)\n\tat org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.run(AbstractWorkerSourceTask.java:75)\n\tat org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:181)\n\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
    }
  ],
  "type": "source"
}
üîç Status for s3-sink-ipca:
{
  "name": "s3-sink-ipca",
  "connector": {
    "state": "RUNNING",
    "worker_id": "connect:8083"
  },
  "tasks": [],
  "type": "sink"
}
üîç Status for s3-sink-pre:
{
  "name": "s3-sink-pre",
  "connector": {
    "state": "RUNNING",
    "worker_id": "connect:8083"
  },
  "tasks": [],
  "type": "sink"
}
"
  },
  "tasks": [],
  "type": "sink"
}
