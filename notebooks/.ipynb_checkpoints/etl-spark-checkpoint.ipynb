{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c7a9a6f-50f4-45f8-9f3e-49f46a95e64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask<2.3,>=2.2 in /opt/conda/lib/python3.11/site-packages (2.2.5)\n",
      "Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.11/site-packages (1.1.0)\n",
      "Requirement already satisfied: pyspark in /usr/local/spark/python (3.5.0)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.11/site-packages (1.38.21)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in /opt/conda/lib/python3.11/site-packages (from flask<2.3,>=2.2) (3.1.3)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /opt/conda/lib/python3.11/site-packages (from flask<2.3,>=2.2) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /opt/conda/lib/python3.11/site-packages (from flask<2.3,>=2.2) (2.2.0)\n",
      "Requirement already satisfied: click>=8.0 in /opt/conda/lib/python3.11/site-packages (from flask<2.3,>=2.2) (8.1.7)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.11/site-packages (from pyspark) (0.10.9.7)\n",
      "Requirement already satisfied: botocore<1.39.0,>=1.38.21 in /opt/conda/lib/python3.11/site-packages (from boto3) (1.38.21)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.13.0,>=0.12.0 in /opt/conda/lib/python3.11/site-packages (from boto3) (0.12.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.11/site-packages (from botocore<1.39.0,>=1.38.21->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.11/site-packages (from botocore<1.39.0,>=1.38.21->boto3) (2.0.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from Jinja2>=3.0->flask<2.3,>=2.2) (2.1.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.39.0,>=1.38.21->boto3) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"flask<2.3,>=2.2\" python-dotenv pyspark boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5982fed4-a459-42a5-b1ec-d9c295063292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"XP ETL Pipeline) \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "from pyspark.sql.functions import col, from_unixtime, avg, count\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a1809d9-66d5-43b0-83da-0cb4afb7936c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "aws_access_key = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "aws_secret_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "aws_region = os.getenv(\"S3_REGION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78e2715d-1fde-4f47-8b79-e98edd049cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "hadoop_aws_jar = os.path.join(current_dir, \"hadoop-aws-3.3.4.jar\")\n",
    "aws_sdk_jar = os.path.join(current_dir, \"aws-java-sdk-bundle-1.12.262.jar\")\n",
    "\n",
    "jars_path = f\"{hadoop_aws_jar},{aws_sdk_jar}\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"XP ETL Pipeline - S3 Integration\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config(\"spark.jars\", jars_path) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", aws_access_key)\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", aws_secret_key)\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", f\"s3.{aws_region}.amazonaws.com\")\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.s3a.connection.ssl.enabled\", \"true\")\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.s3a.path.style.access\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca35af7-9dd3-4d72-90bd-0baf142fa36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bronze_path = \"s3a://xp-etl-pipeline/raw/kafka/ipca/postgres-postg_ipca/partition=0/\"\n",
    "\n",
    "try:\n",
    "    df_bronze = spark.read.json(bronze_path)\n",
    "    print(\"Bronze!\")\n",
    "    df_bronze.show()\n",
    "    df_silver.write.mode(\"overwrite\").parquet(\"s3a://xp-etl-pipeline/processed-data/ipca/1 - bronze/\")\n",
    "except Exception as e:\n",
    "    print(f\"Error accessing S3: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3db6065-d1b6-438d-aad4-8e7984e64013",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bronze = df_bronze.select(\"payload.*\")\n",
    "\n",
    "df_silver = df_bronze.dropDuplicates()\n",
    "\n",
    "df_silver = df_silver.withColumn(\"Data_Vencimento\", from_unixtime(col(\"Data_Vencimento\") / 1000, \"yyyy-MM-dd\")) \\\n",
    "                     .withColumn(\"Data_Base\", from_unixtime(col(\"Data_Base\") / 1000, \"yyyy-MM-dd\")) \\\n",
    "                     .withColumn(\"dt_update\", from_unixtime(col(\"dt_update\") / 1000, \"yyyy-MM-dd HH:mm:ss\"))\n",
    "\n",
    "df_silver = df_silver.fillna({\n",
    "    \"PUCompraManha\": 0,\n",
    "    \"PUVendaManha\": 0,\n",
    "    \"PUBaseManha\": 0\n",
    "})\n",
    "\n",
    "print(\"Silver!\")\n",
    "df_silver.show(truncate=False)\n",
    "\n",
    "silver_path = \"s3a://xp-etl-pipeline/processed-data/ipca/2 - silver/\"\n",
    "df_silver.write.mode(\"overwrite\").parquet(silver_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5961b21d-81f9-4ef0-9179-6ef8d7fb0557",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gold = df_silver.groupBy(\"Tipo\").agg(\n",
    "    avg(\"PUCompraManha\").alias(\"Media_PUCompraManha\"),\n",
    "    avg(\"PUVendaManha\").alias(\"Media_PUVendaManha\"),\n",
    "    count(\"*\").alias(\"Total_Registros\")\n",
    ")\n",
    "\n",
    "print(\"Gold!\")\n",
    "df_gold.show(truncate=False)\n",
    "\n",
    "gold_path = \"s3a://xp-etl-pipeline/processed-data/ipca/3 - gold/\"\n",
    "df_gold.write.mode(\"overwrite\").parquet(gold_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
